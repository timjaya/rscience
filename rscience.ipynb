{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of RScience\n",
    "Authors: Tim Kartawijaya and Jing Yi Zhou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "from sklearn.preprocessing import Normalizer\n",
    "import numpy as np\n",
    "import string\n",
    "import copy\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will subsample the data with 32,000 samples for computational purposes (grid searching takes a very long time with 200k samples) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135529\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def random_sample(filename, size=32000, n=167529):\n",
    "    #number of records in file (excludes header)\n",
    "    #the 0-indexed header will not be included in the skip list\n",
    "    skip = sorted(random.sample(range(1,n+1),n-size)) \n",
    "    print(len(skip))\n",
    "    return pd.read_csv(filename, encoding = \"ISO-8859-1\", skiprows=skip)\n",
    "sampled_train = random_sample(\"data/reddit_200k_train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's take a peek at the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>body</th>\n",
       "      <th>score.x</th>\n",
       "      <th>parent_id.x</th>\n",
       "      <th>id</th>\n",
       "      <th>created_utc.x</th>\n",
       "      <th>retrieved_on</th>\n",
       "      <th>REMOVED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Monday: Drug companies stock dives on good new...</td>\n",
       "      <td>5</td>\n",
       "      <td>t3_8o88yr</td>\n",
       "      <td>e02sjhz</td>\n",
       "      <td>1528087570</td>\n",
       "      <td>1532170350</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Well i was wanting to get wasted tonight.  Not...</td>\n",
       "      <td>3</td>\n",
       "      <td>t3_99wi9m</td>\n",
       "      <td>e4rtew8</td>\n",
       "      <td>1535140675</td>\n",
       "      <td>1537893540</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22</td>\n",
       "      <td>New study shows 90% of the comments get remove...</td>\n",
       "      <td>18</td>\n",
       "      <td>t3_7a2pmo</td>\n",
       "      <td>dp6rpcw</td>\n",
       "      <td>1509542898</td>\n",
       "      <td>1512014062</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35</td>\n",
       "      <td>'Max Planck from theÂ Institute for Cognitive ...</td>\n",
       "      <td>15</td>\n",
       "      <td>t3_80psqz</td>\n",
       "      <td>duxc8nz</td>\n",
       "      <td>1519765498</td>\n",
       "      <td>1520318924</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38</td>\n",
       "      <td>Its like this title was created using a rando...</td>\n",
       "      <td>8</td>\n",
       "      <td>t3_9ay822</td>\n",
       "      <td>e4z0wh3</td>\n",
       "      <td>1535462309</td>\n",
       "      <td>1538014665</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               body  score.x  \\\n",
       "0           3  Monday: Drug companies stock dives on good new...        5   \n",
       "1           5  Well i was wanting to get wasted tonight.  Not...        3   \n",
       "2          22  New study shows 90% of the comments get remove...       18   \n",
       "3          35  'Max Planck from theÂ Institute for Cognitive ...       15   \n",
       "4          38  Its like this title was created using a rando...        8   \n",
       "\n",
       "  parent_id.x       id  created_utc.x  retrieved_on  REMOVED  \n",
       "0   t3_8o88yr  e02sjhz     1528087570    1532170350     True  \n",
       "1   t3_99wi9m  e4rtew8     1535140675    1537893540    False  \n",
       "2   t3_7a2pmo  dp6rpcw     1509542898    1512014062     True  \n",
       "3   t3_80psqz  duxc8nz     1519765498    1520318924    False  \n",
       "4   t3_9ay822  e4z0wh3     1535462309    1538014665     True  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from above, for features we have the user id, score, and time retrieved on. Score may be greatly indicative of whether a post is inappropriate for the thread (assuming scorers are hard core r/science users). Let us see if that is the case below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = sampled_train['score.x']\n",
    "removed = sampled_train['REMOVED']\n",
    "score_removed = score[removed==True]\n",
    "score_not_removed = score[removed==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.9511e+04, 8.2000e+01, 3.6000e+01, 1.2000e+01, 1.1000e+01,\n",
       "        6.0000e+00, 6.0000e+00, 3.0000e+00, 3.0000e+00, 1.0000e+00]),\n",
       " array([  -78. ,  1274.3,  2626.6,  3978.9,  5331.2,  6683.5,  8035.8,\n",
       "         9388.1, 10740.4, 12092.7, 13445. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(score_not_removed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1.2299e+04, 1.8000e+01, 6.0000e+00, 2.0000e+00, 2.0000e+00,\n",
       "        1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00]),\n",
       " array([ -132. ,  1637.7,  3407.4,  5177.1,  6946.8,  8716.5, 10486.2,\n",
       "        12255.9, 14025.6, 15795.3, 17565. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(score_removed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, let us only use content of the body as features for the model, since we want our model to act quickly (don't need to wait for user scores). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TimGimi/miniconda3/lib/python3.7/site-packages/pandas/core/frame.py:3381: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>REMOVED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday: Drug companies stock dives on good new...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Well i was wanting to get wasted tonight.  Not...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New study shows 90% of the comments get remove...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'Max Planck from theÂ Institute for Cognitive ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Its like this title was created using a rando...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  REMOVED\n",
       "0  Monday: Drug companies stock dives on good new...        1\n",
       "1  Well i was wanting to get wasted tonight.  Not...        0\n",
       "2  New study shows 90% of the comments get remove...        1\n",
       "3  'Max Planck from theÂ Institute for Cognitive ...        0\n",
       "4  Its like this title was created using a rando...        1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_train = sampled_train[['body', 'REMOVED']]\n",
    "my_test = pd.read_csv('data/reddit_200k_test.csv', \n",
    "                      encoding = \"ISO-8859-1\")[['body', 'REMOVED']]\n",
    "my_train[['REMOVED']] = (my_train[['REMOVED']] == True).astype(int)\n",
    "my_test[['REMOVED']] = (my_test[['REMOVED']] == True).astype(int)\n",
    "my_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>REMOVED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi Larpo_Nadar, your submission has been remov...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So out of every 10,000 children with autism wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When I was pregnant, I was warned against eati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Imagine if this find was the bug that eradicat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Is it a myth that the math says it would take ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  REMOVED\n",
       "0  Hi Larpo_Nadar, your submission has been remov...        1\n",
       "1  So out of every 10,000 children with autism wh...        0\n",
       "2  When I was pregnant, I was warned against eati...        0\n",
       "3  Imagine if this find was the bug that eradicat...        1\n",
       "4  Is it a myth that the math says it would take ...        0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean dataset of punctuations, whitespace, etc.\n",
    "\n",
    "(TODO: May be redundant since BoW from sklearn does this for you)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(df_orig):\n",
    "    df = df_orig.copy()\n",
    "    # Removing punctuations\n",
    "    df['body'] = df['body'].str.replace('[^\\w\\s]','')\n",
    "    # Remove digits\n",
    "    df['body'] = df['body'].str.replace('\\d+', '', regex=True, case=False)\n",
    "    # Lower casing every words\n",
    "    df['body'] = df['body'].str.lower()\n",
    "    return df\n",
    "\n",
    "my_train_cleaned = clean_df(my_train)\n",
    "my_test_cleaned = clean_df(my_test)\n",
    "\n",
    "X_train = my_train_cleaned['body']\n",
    "y_train = my_train_cleaned['REMOVED']\n",
    "X_test = my_test_cleaned['body']\n",
    "y_test = my_test_cleaned['REMOVED']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see below, the data is imbalanced. To handle this, we will use model class_weights to balance the dataset as we train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of X_train:  32000\n",
      "class balance:  [19671 12329]\n",
      "length of X_test:  55843\n",
      "class balance:  [34565 21278]\n"
     ]
    }
   ],
   "source": [
    "print(\"length of X_train: \", len(X_train))\n",
    "print(\"class balance: \", np.bincount(y_train))\n",
    "print(\"length of X_test: \", len(X_test))\n",
    "print(\"class balance: \", np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: Bag of Words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline: Bag-of-Words, Logistic Regression\n",
    "As a baseline, we will use CountVectorizer to create a bag of words, and use logistic regression as our linear baseline. Since we would like a balance between finding a troll and not misclassifying in this problem (want to remove most trollers but not remove too many true posts), we will use roc_auc as our scoring metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...andom_state=None, refit=True, scoring='roc_auc',\n",
       "           solver='lbfgs', tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = Pipeline([\n",
    "     ('vect', CountVectorizer()),\n",
    "     ('clf', LogisticRegressionCV(cv=5, max_iter=4000, \n",
    "                                  class_weight='balanced', penalty='l2', \n",
    "                                  scoring='roc_auc', solver = 'lbfgs'))\n",
    "     ])\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7048077323079116"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CROSS VALIDATION SCORE\n",
    "cv_scores = [np.mean(x) for x in lr.steps[1][1].scores_[1]]\n",
    "cv_scores = []\n",
    "for i in range(len(lr.steps[1][1].scores_[1][0])):\n",
    "    cv_scores.append(np.mean(lr.steps[1][1].scores_[1][:,i]))\n",
    "best_cv_score=max(cv_scores)\n",
    "best_cv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see above that the cross-validation score for the baseline model is not too bad, better than random guessing (~<50% on most metrics). Now let's try to see if other variations of the model (with tfidf, n-grams, etc.) works better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try using n-grams, characters, tf-idf rescaling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With TFIDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results below, we see that TFIDF doesn't have a significant impact on the scores, compared to the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip...=None,\n",
       "           refit=True, scoring='roc_auc', solver='lbfgs', tol=0.0001,\n",
       "           verbose=0))])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "lr_tfidf = Pipeline([\n",
    "     ('vect', CountVectorizer()),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', LogisticRegressionCV(cv=5, n_jobs=-1, max_iter=4000, \n",
    "                                  class_weight='balanced', penalty='l2', \n",
    "                                  scoring='roc_auc', solver = 'lbfgs'))\n",
    "     ])\n",
    "lr_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7135360152384247"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CROSS VALIDATION SCORE\n",
    "cv_scores = [np.mean(x) for x in lr_tfidf.steps[2][1].scores_[1]]\n",
    "cv_scores = []\n",
    "for i in range(len(lr_tfidf.steps[2][1].scores_[1][0])):\n",
    "    cv_scores.append(np.mean(lr_tfidf.steps[2][1].scores_[1][:,i]))\n",
    "best_cv_score=max(cv_scores)\n",
    "best_cv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see here, our cv_scores improved by about 1%, which isn't that significant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Word N-Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now see how our model works with Word/Character N-Grams. First, let's see how our model works if we only use word n grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_word = Pipeline([\n",
    "     ('vect', CountVectorizer(analyzer='word')),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', LogisticRegression(class_weight='balanced', \n",
    "                                penalty='l2', max_iter=4000, \n",
    "                                solver = 'lbfgs'))\n",
    "     ])\n",
    "\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (1, 5), (1, 7), (2, 3), (2, 5), (3, 8), (5, 5)],\n",
    "    'vect__min_df': [1, 2, 3],\n",
    "    'clf__C': [100, 10, 1, 1e-1, 1e-2, 1e-3]\n",
    "     }\n",
    "\n",
    "gs_clf_word = GridSearchCV(text_clf_word, parameters, \n",
    "                           cv=5, n_jobs=-1, scoring = \"roc_auc\")\n",
    "gs_clf_word.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:  {'clf__C': 1, 'vect__min_df': 2, 'vect__ngram_range': (1, 2)}\n",
      "Best:  0.7215608461131218\n"
     ]
    }
   ],
   "source": [
    "# TRAIN/CROSS-VAL score\n",
    "print('Best Params: ', gs_clf_word.best_params_)\n",
    "print('Best: ', gs_clf_word.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our cross validation score increased slightly again by about 1%. Next, let's see how our model works if we use character ngrams. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With Character N-Grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_char = Pipeline([\n",
    "     ('vect', CountVectorizer(analyzer='char_wb')),\n",
    "     ('tfidf', TfidfTransformer()),\n",
    "     ('clf', LogisticRegression(class_weight='balanced', \n",
    "                                penalty='l2', max_iter=4000, \n",
    "                                solver = 'lbfgs'))\n",
    "     ])\n",
    "\n",
    "parameters = {\n",
    "    'vect__ngram_range': [(1, 1), (1, 2), (1, 5), (1, 7), (2, 3), (2, 5), (3, 8), (5, 5)],\n",
    "    'vect__min_df': [1, 2, 3],\n",
    "    'clf__C': [100, 10, 1, 1e-1, 1e-2, 1e-3]\n",
    "     }\n",
    "\n",
    "gs_clf_char = GridSearchCV(text_clf_char, parameters, \n",
    "                           cv=5, n_jobs=-1, scoring = \"roc_auc\")\n",
    "gs_clf_char.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:  {'clf__C': 1, 'vect__min_df': 3, 'vect__ngram_range': (1, 7)}\n",
      "Best:  0.7351486932766884\n"
     ]
    }
   ],
   "source": [
    "# CROSS VAL SCORE\n",
    "print('Best Params: ', gs_clf_char.best_params_)\n",
    "print('Best: ', gs_clf_char.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our character n-grams improved our results even more! So we will use character n-grams in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "As we can see above, we found that our character n-grams and tfidf improved our model from the baseline by about 3%. So we will use such settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Let us now try to derive more features from this dataset (e.g. Html, length, punctuation, capitalization) to try to improve the score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if driving additional features will improve our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_derived = my_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capitalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Percentage of Capitalized Letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_upper(sentence):\n",
    "    count = 0\n",
    "    for letter in sentence: \n",
    "        if letter.isupper():\n",
    "            count += 1\n",
    "    \n",
    "    return count/len(sentence)\n",
    "\n",
    "count_upper_v = np.vectorize(count_upper)\n",
    "train_derived['capital_letter_pct'] = count_upper_v(train_derived['body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of All Capitalized Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_upper_words(sentence):\n",
    "    # remove punctuation\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    count = 0\n",
    "    words = sentence.split(' ')\n",
    "    for w in words:\n",
    "        allcaps = True\n",
    "        if w.isupper() and len(w) > 1:\n",
    "            count += 1\n",
    "    return count\n",
    "count_upper_words_v = np.vectorize(count_upper_words)\n",
    "train_derived['capital_word_count'] = count_upper_words_v(train_derived['body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length \n",
    "Next, let's count the length of the sentence itself as well as the longest word in the sentence. First, let's remove websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_without_url = train_derived.copy()\n",
    "# number of digits\n",
    "train_derived['digits_count'] = train_without_url['body'].str.count('\\d') \n",
    "# number of alphabets\n",
    "train_derived['alphabet_count'] = train_without_url['body'].str.count('[A-Za-z]') \n",
    "train_derived['sentence_length'] = train_without_url['body'].str.len()\n",
    "\n",
    "def longest_word_n(sentence):\n",
    "    sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = sentence.split(' ')\n",
    "    return max([len(w) for w in words])\n",
    "longest_word_n_v = np.vectorize(longest_word_n)\n",
    "train_derived['longest_word_length'] = longest_word_n_v(train_without_url['body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Websites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_derived['links_count'] = train_derived['body'].str.count('http')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top Level Domains Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_domains = ['\\.com','\\.org','\\.edu','\\.gov','\\.net','\\.io']\n",
    "for i in top_domains:\n",
    "    colname = 'count_'+i\n",
    "    train_derived[colname] = train_derived.body.str.count(i)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation = ['!','\\?','\\.','#',':',';','@','\\(','\\)','\\'','&','\\$',';\\)',':\\)']\n",
    "for i in punctuation:\n",
    "    colname = 'count_'+i\n",
    "    train_derived[colname] = train_derived.body.str.count(i)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derive_new_features(original):\n",
    "    df = original.copy()\n",
    "    # capital letter\n",
    "    df['capital_letter_pct'] = count_upper_v(df['body'])\n",
    "    df['capital_word_count'] = count_upper_words_v(df['body'])\n",
    "    # websites\n",
    "    df['links_count'] = df['body'].str.count('http')\n",
    "    top_domains = ['\\.com','\\.org','\\.edu','\\.gov','\\.net','\\.io']\n",
    "    for i in top_domains:\n",
    "        colname = 'count_'+i\n",
    "        df[colname] = df.body.str.count(i)\n",
    "    # length\n",
    "    df['digits_count'] = df['body'].str.count('\\d')\n",
    "    df['alphabet_count'] = df['body'].str.count('[A-Za-z]')\n",
    "    df['sentence_length'] = df['body'].str.len()\n",
    "    df['longest_word_length'] = longest_word_n_v(df['body'])\n",
    "    # punctuation\n",
    "    punctuation = ['!','\\?','\\.','#',':',';','@','\\(','\\)','\\'','&','\\$',';\\)',':\\)']\n",
    "    for i in punctuation:\n",
    "        colname = 'count_'+i\n",
    "        df[colname] = df.body.str.count(i)    \n",
    "    return df\n",
    "train_derived = derive_new_features(my_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Score\n",
    "Let's see if these new derived features increased our classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_derived = train_derived.drop(['REMOVED'], axis = 1)\n",
    "y_train_derived = train_derived['REMOVED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_col = 'body'\n",
    "others_col = list(np.delete(X_train_derived.columns.values, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "class SparseTransformer(TransformerMixin):\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return csr_matrix(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "text_preprocess = Pipeline(steps=[\n",
    "     ('vect', CountVectorizer(analyzer='char_wb')),\n",
    "     ('tfidf', TfidfTransformer())\n",
    "])\n",
    "\n",
    "other_preprocess = Pipeline(steps=[\n",
    "    ('sparse', SparseTransformer())\n",
    "])\n",
    "\n",
    "col_transformer = ColumnTransformer(\n",
    "    [('text',text_preprocess, text_col),\n",
    "    ('other',other_preprocess, others_col)]\n",
    ")\n",
    "\n",
    "final_pipeline = Pipeline(steps=[\n",
    "    ('columntransformer', col_transformer),\n",
    "    ('logisticregression', LogisticRegression(class_weight='balanced', \n",
    "                                              max_iter=4000, \n",
    "                                              solver = 'lbfgs'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'columntransformer__text__vect__ngram_range': [(1, 1), (1, 2), (1, 5), (1, 7), (2, 3), (2, 5), (3, 8), (5, 5)],\n",
    "    'columntransformer__text__vect__min_df': [1, 2, 3],\n",
    "    'logisticregression__C': [100, 10, 1, 1e-1, 1e-2, 1e-3]\n",
    "     }\n",
    "\n",
    "gs_derived = GridSearchCV(final_pipeline, parameters, cv=5, \n",
    "                          n_jobs=-1, scoring = \"roc_auc\")\n",
    "gs_derived.fit(X_train_derived, y_train_derived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:  {'columntransformer__text__vect__min_df': 2, 'columntransformer__text__vect__ngram_range': (1, 5), 'logisticregression__C': 1}\n",
      "Best:  0.7521540955881347\n"
     ]
    }
   ],
   "source": [
    "print('Best Params: ', gs_derived.best_params_)\n",
    "print('Best: ', gs_derived.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Our derived features improves our score by yet another 1%. In this case, let's include our derived features!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Vectors\n",
    "Now we will try to use a pretrained word-embedding (Google News Gensim) to model our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download here https://github.com/mmihaltz/word2vec-GoogleNews-vectors\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_gensim = train_derived_clean.drop(['REMOVED'], axis = 1)\n",
    "y_train_gensim = train_derived_clean['REMOVED']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have to remove words that are not in our dictionary and remove empty lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_texts = [[token for token in doc.lower().split() if token in model] \\\n",
    "                 for doc in X_train_gensim['body']]\n",
    "index_to_remove = [len(i) for i in x_train_texts]\n",
    "x_train_texts = [i for i in x_train_texts if len(i) > 0]\n",
    "x_train_new = np.vstack([np.mean(model[doc], axis=0) for doc in x_train_texts])\n",
    "y_index = [i != 0 for i in index_to_remove]\n",
    "y_train_new = y_train_gensim[y_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_other = X_train_gensim.drop(['body'], axis=1)[y_index]\n",
    "X_train_gensim = np.concatenate((x_train_new, X_other.values), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_texts = [[token for token in doc.lower().split() if token in model] \\\n",
    "                for doc in X_test_gensim['body']]\n",
    "index_to_remove = [len(i) for i in x_test_texts]\n",
    "x_test_texts = [i for i in x_test_texts if len(i) > 0]\n",
    "x_test_new = np.vstack([np.mean(model[doc], axis=0) for doc in x_test_texts])\n",
    "y_index = [i != 0 for i in index_to_remove]\n",
    "y_test_new = y_test_gensim[y_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running our w2v model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/TimGimi/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV(Cs=10, class_weight='balanced', cv=5, dual=False,\n",
       "           fit_intercept=True, intercept_scaling=1.0, max_iter=100,\n",
       "           multi_class='warn', n_jobs=-1, penalty='l2', random_state=None,\n",
       "           refit=True, scoring='roc_auc', solver='lbfgs', tol=0.0001,\n",
       "           verbose=0)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_w2v = LogisticRegressionCV(cv=5, class_weight='balanced', \n",
    "                              penalty='l2', n_jobs=-1, \n",
    "                              scoring='roc_auc', max_iter=100,\n",
    "                              solver = 'lbfgs')\n",
    "lr_w2v.fit(X_train_gensim, y_train_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7017863157479809"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CROSS VALIDATION SCORE\n",
    "cv_scores = [np.mean(x) for x in lr_w2v.scores_[1]]\n",
    "cv_scores = []\n",
    "for i in range(len(lr_w2v.scores_[1])):\n",
    "    cv_scores.append(np.mean(lr_w2v.scores_[1][:,i]))\n",
    "best_cv_score=max(cv_scores)\n",
    "best_cv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Our word2vec model is worse by 5%! This is probably due to gensim 'playing down' the effects of mispellings due to the embeddings compared to the bag of words, which can be indicative of a troll. Therefore, we will choose our improved bag of words model as our best model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Model : Test Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have found our best model (bag-of-words), let's see how it performs to our out of sample dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_derived = derive_new_features(my_test)\n",
    "X_test_derived = test_derived.drop(['REMOVED'], axis = 1)\n",
    "y_test_derived = test_derived['REMOVED']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7937    0.6838    0.7346     34565\n",
      "           1     0.5806    0.7112    0.6393     21278\n",
      "\n",
      "   micro avg     0.6942    0.6942    0.6942     55843\n",
      "   macro avg     0.6871    0.6975    0.6870     55843\n",
      "weighted avg     0.7125    0.6942    0.6983     55843\n",
      "\n",
      "Confusion matrix: \n",
      "       0      1\n",
      "0  23635  10930\n",
      "1   6145  15133\n",
      "ROC-AUC Score: \n",
      "0.6974941176376211\n"
     ]
    }
   ],
   "source": [
    "y_pred = gs_derived.predict(X_test_derived)\n",
    "print(\"Classification report: \")\n",
    "print(classification_report(y_test_derived, y_pred, digits=4))\n",
    "print(\"Confusion matrix: \")\n",
    "print(pd.DataFrame(confusion_matrix(y_test_derived, y_pred)))\n",
    "print(\"ROC-AUC Score: \")\n",
    "print(roc_auc_score(y_test_derived, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test ROC_AUC from our model is 69.7%, which is not terrible considering our alternative is only random guessing. \n",
    "\n",
    "## Production Considerations\n",
    "\n",
    "Our model is not a highly accurate model, thus if this model was to be implemented it should act as a 'flagging tool' and give human administrators the power to decide whether a post should be removed/not, rather than completely automating the removal procedure. \n",
    "\n",
    "## Next Steps \n",
    "\n",
    "We can try to improve this model by deriving/including more features (traverse the user id, score), add more computation power to be able to grid search a larger dataset, and use more advanced models/different word embeddings."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
